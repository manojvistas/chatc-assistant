# ğŸ§  Chatc Assistant - AI Chatbot with Flask & OpenAI (Deployable on Render)

Chatc Assistant is a simple web-based chatbot using Flask, HTML/CSS/JS frontend, and OpenAI GPT-3.5/4 for real-time conversation. This project is deployed on Render (free cloud hosting).

---

## ğŸ§  Features

* Conversational chatbot using OpenAI LLM
* Modern UI with Tailwind CSS
* Chat history stored in browser (localStorage)
* Flask backend API
* Easy to deploy on Render

---

## ğŸŒ Live Demo

> \[ğŸ”— https://chatc-assistant.onrender.com]

---

## ğŸ“ Folder Structure

```
project/
â”‚
â”œâ”€â”€ ollama_llm_flask.py       # Flask backend
â”œâ”€â”€ requirements.txt          # Python dependencies
â”œâ”€â”€ Procfile                  # Tells Render how to run app
â”‚
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html            # Frontend HTML
â”‚
â”œâ”€â”€ static/
â”‚   â”œâ”€â”€ styles.css            # Styling
â”‚   â””â”€â”€ chat.js               # Chat logic
```

---

## ğŸ› ï¸ Installation (Local Testing)

```bash
git clone https://github.com/your-username/chatc-assistant.git
cd chatc-assistant

# Create a virtual environment (optional)
python -m venv venv
source venv/bin/activate  # or venv\Scripts\activate on Windows

# Install dependencies
pip install -r requirements.txt

# Add your OpenAI API key
export OPENAI_API_KEY='your_key_here'  # Use .env in development

# Run the app
python ollama_llm_flask.py
```

Go to `http://localhost:5000` to test.

---

## ğŸš€ Deployment on Render (Free Cloud Hosting)

### 1. Push this project to GitHub

Make sure it includes:

* `requirements.txt`
* `Procfile`
* `templates/index.html`
* `static/` folder
* Updated `ollama_llm_flask.py`

### 2. Sign in to \[[Render.com](https://render.com)]\([https://render.com](https://render.com))

### 3. Create New â†’ Web Service

* Connect your GitHub repo
* Build Command: `pip install -r requirements.txt`
* Start Command: `python ollama_llm_flask.py`
* Environment: Python 3.x
* Instance Type: Free

### 4. Set Environment Variables

In Render dashboard â†’ **Environment** tab:

```
Key: OPENAI_API_KEY
Value: your_openai_key_here
```

---

## ğŸ§  Using OpenAI (Instead of Ollama)

### Replace this in `ollama_llm_flask.py`:

```python
from langchain.chat_models import ChatOpenAI
llm = ChatOpenAI(model_name="gpt-3.5-turbo", openai_api_key=os.environ["OPENAI_API_KEY"])
```

Thatâ€™s all. The chatbot will now respond using GPT-3.5!

---

## âœ… requirements.txt (Make Sure It Has These)

```txt
flask
flask-cors
langchain
openai
```

---

## âš ï¸ Notes

* Don't push your API key to GitHub!
* Use `.env` locally and environment variables on Render
* GPT-3.5 is fast and works great on the free tier

---

## ğŸ“© Contact

Made by [Manoj R] | B.Tech Student | Cloud & AI Enthusiast ğŸŒ©ï¸
